{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U google-generativeai\n\nimport google.generativeai as genai\nfrom kaggle_secrets import UserSecretsClient\n\n# 1. Setup\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=api_key)\n\n# 2. List Models\nprint(\"SEARCHING FOR AVAILABLE MODELS...\")\nprint(\"-\" * 30)\n\ntry:\n    available_models = []\n    for m in genai.list_models():\n        if 'generateContent' in m.supported_generation_methods:\n            print(f\"‚úÖ FOUND: {m.name}\")\n            available_models.append(m.name)\n            \n    if not available_models:\n        print(\"‚ùå No models found. Your API Key might be invalid or restricted.\")\n    else:\n        print(\"-\" * 30)\n        print(f\"RECOMMENDED: Please use '{available_models[0]}' in your code.\")\n        \nexcept Exception as e:\n    print(f\"Error listing models: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T08:08:54.782492Z","iopub.execute_input":"2025-12-01T08:08:54.782910Z","iopub.status.idle":"2025-12-01T08:08:58.523671Z","shell.execute_reply.started":"2025-12-01T08:08:54.782864Z","shell.execute_reply":"2025-12-01T08:08:58.522344Z"}},"outputs":[{"name":"stdout","text":"SEARCHING FOR AVAILABLE MODELS...\n------------------------------\n‚úÖ FOUND: models/gemini-2.5-pro-preview-03-25\n‚úÖ FOUND: models/gemini-2.5-flash\n‚úÖ FOUND: models/gemini-2.5-pro-preview-05-06\n‚úÖ FOUND: models/gemini-2.5-pro-preview-06-05\n‚úÖ FOUND: models/gemini-2.5-pro\n‚úÖ FOUND: models/gemini-2.0-flash-exp\n‚úÖ FOUND: models/gemini-2.0-flash\n‚úÖ FOUND: models/gemini-2.0-flash-001\n‚úÖ FOUND: models/gemini-2.0-flash-exp-image-generation\n‚úÖ FOUND: models/gemini-2.0-flash-lite-001\n‚úÖ FOUND: models/gemini-2.0-flash-lite\n‚úÖ FOUND: models/gemini-2.0-flash-lite-preview-02-05\n‚úÖ FOUND: models/gemini-2.0-flash-lite-preview\n‚úÖ FOUND: models/gemini-2.0-pro-exp\n‚úÖ FOUND: models/gemini-2.0-pro-exp-02-05\n‚úÖ FOUND: models/gemini-exp-1206\n‚úÖ FOUND: models/gemini-2.0-flash-thinking-exp-01-21\n‚úÖ FOUND: models/gemini-2.0-flash-thinking-exp\n‚úÖ FOUND: models/gemini-2.0-flash-thinking-exp-1219\n‚úÖ FOUND: models/gemini-2.5-flash-preview-tts\n‚úÖ FOUND: models/gemini-2.5-pro-preview-tts\n‚úÖ FOUND: models/learnlm-2.0-flash-experimental\n‚úÖ FOUND: models/gemma-3-1b-it\n‚úÖ FOUND: models/gemma-3-4b-it\n‚úÖ FOUND: models/gemma-3-12b-it\n‚úÖ FOUND: models/gemma-3-27b-it\n‚úÖ FOUND: models/gemma-3n-e4b-it\n‚úÖ FOUND: models/gemma-3n-e2b-it\n‚úÖ FOUND: models/gemini-flash-latest\n‚úÖ FOUND: models/gemini-flash-lite-latest\n‚úÖ FOUND: models/gemini-pro-latest\n‚úÖ FOUND: models/gemini-2.5-flash-lite\n‚úÖ FOUND: models/gemini-2.5-flash-image-preview\n‚úÖ FOUND: models/gemini-2.5-flash-image\n‚úÖ FOUND: models/gemini-2.5-flash-preview-09-2025\n‚úÖ FOUND: models/gemini-2.5-flash-lite-preview-09-2025\n‚úÖ FOUND: models/gemini-3-pro-preview\n‚úÖ FOUND: models/gemini-3-pro-image-preview\n‚úÖ FOUND: models/nano-banana-pro-preview\n‚úÖ FOUND: models/gemini-robotics-er-1.5-preview\n‚úÖ FOUND: models/gemini-2.5-computer-use-preview-10-2025\n------------------------------\nRECOMMENDED: Please use 'models/gemini-2.5-pro-preview-03-25' in your code.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# --- 1. FORCE INSTALL & SETUP ---\n!pip install -q -U google-generativeai markdown gradio\n\nimport google.generativeai as genai\nfrom kaggle_secrets import UserSecretsClient\nimport json\nimport os\nimport time\nimport gradio as gr\n\n# --- 2. CONFIGURATION ---\nMODEL_NAME = \"gemini-2.5-flash\"\n\ntry:\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n    genai.configure(api_key=api_key)\nexcept Exception as e:\n    print(f\"Error: {e}\")\n\ngeneration_config = {\n    \"temperature\": 0.3,\n    \"max_output_tokens\": 8192,\n}\nmodel = genai.GenerativeModel(MODEL_NAME, generation_config=generation_config)\n\n# --- 3. AGENT LOGIC ---\nclass StudyGenieBot:\n    def __init__(self):\n        self.reset()\n    \n    def reset(self):\n        self.state = {\n            \"mode\": \"WAITING_TOPIC\",\n            \"syllabus\": [],\n            \"topic\": \"\",\n            \"module_idx\": 0,\n            \"quiz_data\": [],\n            \"quiz_idx\": 0,\n            \"quiz_score\": 0,\n            \"current_lesson_text\": \"\"\n        }\n\n    def generate_plan(self, topic):\n        prompt = f\"\"\"\n        Act as a University Dean. Create a 'Zero-to-Hero' syllabus for: '{topic}'.\n        Rules: 12 Modules. Beginner to Advanced.\n        Return JSON: {{ \"modules\": [\"1. Title\", ... \"12. Title\"] }}\n        \"\"\"\n        try:\n            response = model.generate_content(prompt)\n            text = response.text.strip().replace('```json', '').replace('```', '')\n            data = json.loads(text)\n            return data['modules']\n        except:\n            return [\"Basics\", \"Intermediate\", \"Advanced Concepts\"]\n\n    def generate_lesson(self, topic, module):\n        prompt = f\"\"\"\n        Act as a Professor. Write a DEEP-DIVE textbook chapter.\n        Topic: {topic}. Chapter: {module}.\n        Requirements:\n        1. Long, detailed, use headers, analogies, and code examples.\n        2. EXTREMELY IMPORTANT: End with a section called '## üîë Quick Summary' that lists 5 bullet points for recall.\n        \"\"\"\n        response = model.generate_content(prompt)\n        return response.text\n\n    def generate_quiz(self, lesson):\n        prompt = f\"\"\"\n        Act as an Examiner. Create 3 Progressive Questions (Easy, Med, Hard).\n        Based on: {lesson[:6000]}\n        Return JSON list: [{{ \"question\": \"...\", \"options\": [\"A)...\", \"B)...\"], \"correct_letter\": \"A\" }}]\n        Randomize correct answers.\n        \"\"\"\n        try:\n            response = model.generate_content(prompt)\n            text = response.text.strip().replace('```json', '').replace('```', '')\n            return json.loads(text)\n        except:\n            return []\n\n    def respond(self, message):\n        mode = self.state[\"mode\"]\n\n        if message.lower() == \"/reset\":\n            self.reset()\n            return \"‚ôªÔ∏è System Reset. What topic would you like to master today?\"\n\n        if mode == \"WAITING_TOPIC\":\n            self.state[\"topic\"] = message\n            yield f\"‚öôÔ∏è **Architect Agent:** Designing rigorous syllabus for '{message}'... Please wait.\"\n            \n            syllabus = self.generate_plan(message)\n            self.state[\"syllabus\"] = syllabus\n            self.state[\"mode\"] = \"PLAN_REVIEW\"\n            \n            plan_str = \"\\n\".join([f\"**{m}**\" for m in syllabus])\n            yield f\"### üìò Course Enrolled: {message}\\n\\nHere is your Roadmap:\\n\\n{plan_str}\\n\\nType **'Start'** to begin Module 1.\"\n\n        elif mode == \"PLAN_REVIEW\":\n            if \"start\" in message.lower():\n                self.state[\"mode\"] = \"LEARNING\"\n                yield from self.run_teaching_step()\n            else:\n                yield \"Type 'Start' to begin the course, or '/reset' to pick a new topic.\"\n\n        elif mode == \"QUIZ\":\n            current_q = self.state[\"quiz_data\"][self.state[\"quiz_idx\"]]\n            correct = current_q[\"correct_letter\"]\n            user_ans = message.strip().upper()\n            \n            feedback = \"\"\n            if user_ans == correct:\n                feedback = f\"‚úÖ **Correct!**\"\n                self.state[\"quiz_score\"] += 1\n            else:\n                feedback = f\"‚ùå **Incorrect.** The answer was {correct}.\"\n            \n            self.state[\"quiz_idx\"] += 1\n            \n            if self.state[\"quiz_idx\"] < len(self.state[\"quiz_data\"]):\n                next_q = self.state[\"quiz_data\"][self.state[\"quiz_idx\"]]\n                q_text = self.format_question(next_q, self.state[\"quiz_idx\"]+1)\n                yield f\"{feedback}\\n\\n---\\n\\n{q_text}\"\n            else:\n                score = self.state[\"quiz_score\"]\n                total = len(self.state[\"quiz_data\"])\n                \n                if score >= 2:\n                    result_msg = f\"{feedback}\\n\\n### üéâ Passed! Score: {score}/{total}\\nYou have mastered this module.\"\n                    yield result_msg + \"\\n\\nType **'Next'** to proceed to the next module.\"\n                    self.state[\"mode\"] = \"NEXT_MODULE_WAIT\"\n                else:\n                    result_msg = f\"{feedback}\\n\\n### ‚ö†Ô∏è Failed. Score: {score}/{total}\\nYou must review the material and try again.\"\n                    yield result_msg + \"\\n\\nType **'Retry'** to read the lesson again.\"\n                    self.state[\"mode\"] = \"REMEDIAL_WAIT\"\n\n        elif mode == \"NEXT_MODULE_WAIT\":\n            if \"next\" in message.lower():\n                self.state[\"module_idx\"] += 1\n                if self.state[\"module_idx\"] >= len(self.state[\"syllabus\"]):\n                    yield \"# üéì CONGRATULATIONS! You have officially completed the entire course.\"\n                    self.reset()\n                else:\n                    self.state[\"mode\"] = \"LEARNING\"\n                    yield from self.run_teaching_step()\n            else:\n                yield \"Type 'Next' to continue.\"\n        \n        elif mode == \"REMEDIAL_WAIT\":\n            if \"retry\" in message.lower():\n                self.state[\"mode\"] = \"LEARNING\"\n                yield \"üîÑ **Reloading Lesson for Review...**\"\n                yield from self.run_teaching_step(refresh=False)\n            else:\n                yield \"Type 'Retry' to try again.\"\n\n    def run_teaching_step(self, refresh=True):\n        idx = self.state[\"module_idx\"]\n        module_title = self.state[\"syllabus\"][idx]\n        topic = self.state[\"topic\"]\n        \n        if refresh:\n            yield f\"## üìñ Module {idx+1}: {module_title}\\n\\n**Professor Agent:** Writing textbook chapter... (This may take 10s)\"\n            lesson = self.generate_lesson(topic, module_title)\n            self.state[\"current_lesson_text\"] = lesson\n        else:\n            lesson = self.state[\"current_lesson_text\"]\n        \n        yield f\"## üìñ Module {idx+1}: {module_title}\\n\\n{lesson}\\n\\n---\\n\\nGenerating Quiz...\"\n        \n        quiz_data = self.generate_quiz(lesson)\n        if quiz_data:\n            self.state[\"quiz_data\"] = quiz_data\n            self.state[\"quiz_idx\"] = 0\n            self.state[\"quiz_score\"] = 0\n            self.state[\"mode\"] = \"QUIZ\"\n            \n            first_q = quiz_data[0]\n            q_text = self.format_question(first_q, 1)\n            yield f\"## üìñ Module {idx+1}: {module_title}\\n\\n{lesson}\\n\\n---\\n\\n### üìù Pop Quiz\\n{q_text}\"\n        else:\n            self.state[\"mode\"] = \"NEXT_MODULE_WAIT\"\n            yield f\"{lesson}\\n\\n(No quiz generated). Type 'Next' to continue.\"\n\n    def format_question(self, q_obj, num):\n        opts = \"\\n\".join(q_obj['options'])\n        return f\"**Q{num}: {q_obj['question']}**\\n{opts}\\n\\n*(Type A, B, C, or D)*\"\n\n# --- 4. UI LAUNCHER (UNIVERSAL LIST FORMAT) ---\nbot = StudyGenieBot()\n\n# Initial Greeting\ninitial_history = [\n    [None, \"üëã **Welcome to StudyGenie Pro!**\\n\\nI am your Personal Learning Concierge. I will design a full 'Zero-to-Hero' course for you, teach you everyday, and test your knowledge.\\n\\n**Type a topic below to begin (e.g., 'Python', 'Digital Marketing').**\"]\n]\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# üßû‚Äç‚ôÇÔ∏è StudyGenie Pro\")\n    \n    # Using Standard List format (Works on ALL Gradio versions)\n    chatbot = gr.Chatbot(value=initial_history, height=600)\n    \n    with gr.Row():\n        msg = gr.Textbox(\n            scale=4,\n            show_label=False, \n            placeholder=\"Type your topic here (e.g. 'Advanced Python') and press Enter...\"\n        )\n        clear = gr.Button(\"Reset\", scale=1)\n\n    # Handler for List of Lists [[user, bot]]\n    def bot_response(user_message, history):\n        if user_message.strip() == \"\":\n            return \"\", history\n            \n        # Append User Message\n        history = history + [[user_message, None]]\n        \n        # Get Generator\n        response_generator = bot.respond(user_message)\n        \n        # Stream Response\n        for partial_response in response_generator:\n            history[-1][1] = partial_response\n            yield \"\", history\n\n    msg.submit(bot_response, [msg, chatbot], [msg, chatbot], queue=False)\n    clear.click(lambda: None, None, chatbot, queue=False)\n\ndemo.queue().launch(share=True, debug=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}